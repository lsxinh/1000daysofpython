{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 0015_Merge text files and Convert Local Time to UTC Time - Real Applications\n",
    "\n",
    "# - 1000 days of Python "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd D:\\DoTWA_Data\\FR201410_NoSBET_Q2\\fr_1014\\Tide\\TideData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,glob\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Observed tide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 S1_201410"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.a Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "from pathlib import Path\n",
    "#input directories\n",
    "indir = r'D:\\OneDrive - Curtin University of Technology Australia\\write\\c3_vU\\Observed_Tide\\S1_201410'\n",
    "#input settings\n",
    "in_delimiter = ','\n",
    "in_Ext = '.FRE'\n",
    "#Output settings\n",
    "out_header = 'N'\n",
    "out_delimiter = in_delimiter\n",
    "out_colNames=['Day','Time','Tide','unknown','unknown']\n",
    "out_Ext = '.csv'\n",
    "out_fname = Path(indir) / (Path(indir).name + '_Observed_AWST_merge' + out_Ext)\n",
    "colNames = str(out_colNames)[1:-2].replace(\"'\",\"\").replace(', ',out_delimiter)\n",
    "#Write header based on user input choice\n",
    "outfile = open(out_fname,'w')\n",
    "if out_header == 'Y':\n",
    "        outfile.write(colNames+'\\n')\n",
    "else: pass\n",
    "#Merging text files using pure Python\n",
    "all_In = [f.absolute() for f in Path(indir).iterdir() if f.name.endswith(in_Ext) ]\n",
    "\n",
    "for fname in all_In:\n",
    "    if fname != out_fname:\n",
    "        with open(fname,'r') as infile:\n",
    "            for line in infile:\n",
    "                line = line.replace(in_delimiter,out_delimiter)\n",
    "                if line != '\\n': \n",
    "                    outfile.write(line)\n",
    "#                     print(line)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.b Converting Local time to UTC time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\OneDrive - Curtin University of Technology Australia\\write\\c3_vU\\Observed_Tide\\S1_201410\\S1_201410_Observed_AWST_merge.csv \n",
      " D:\\OneDrive - Curtin University of Technology Australia\\write\\c3_vU\\Observed_Tide\\S1_201410\\S1_201410_Observed_UTC_merge.tide\n"
     ]
    }
   ],
   "source": [
    "def LOCAL2UTC_tide(inFile_p,oFile_p):\n",
    "    import os\n",
    "    import sys\n",
    "    from datetime import datetime\n",
    "    from datetime import timedelta\n",
    "    \n",
    "    dt_format1 = \"%Y-%m-%d %H:%M:%S\"\n",
    "    dt_format2 = \"%Y-%m-%d %H:%M:%S %Z%z\"\n",
    "    dt_format3 = \"%d/%m/%Y%H:%M\"\n",
    "    dt_format4 = \"%d/%m/%Y %H:%M\"\n",
    "    dt_format5 = \"%Y-%m-%d %H:%M:%S.000\"\n",
    "    dt_format6_DoTWA = \"%d/%m/%Y,%H:%M:%S\"\n",
    "    \n",
    "    \n",
    "    oFile_w = open(oFile_p,'w')\n",
    "    skip = 0\n",
    "    \n",
    "    with open(inFile_p,'r') as infile:\n",
    "        msg = '--------\\n'\n",
    "        oFile_w.write(msg)\n",
    "        for counter,line in enumerate(infile):\n",
    "            if counter < skip: continue\n",
    "            # if counter < 15:\n",
    "            line = line.strip('\\n')\n",
    "            line_list = line.split(',')\n",
    "            line_list2 = []\n",
    "            for l in line_list: line_list2.append(l.strip(' '))\n",
    "            tide_str = float(line_list2[2])\n",
    "            tide_str = f'{tide_str:.3f}'\n",
    "            dt_str = line_list2[0] + ',' + line_list2[1]\n",
    "            dt_obj_local = datetime.strptime(dt_str, dt_format6_DoTWA)\n",
    "            dt_txt_local = dt_obj_local.strftime(dt_format2)\n",
    "#             print ('Local:',dt_txt_local,'Tide:',tide_str)\n",
    "            \n",
    "            # Convert to UTC (+00)\n",
    "            local_zone = 8\n",
    "            offset_h = -local_zone\n",
    "            offset_h_dt_oj = timedelta(hours = offset_h)\n",
    "            dt_obj_UTC = dt_obj_local + offset_h_dt_oj\n",
    "            dt_txt_UTC = dt_obj_UTC.strftime(dt_format2)\n",
    "#             print ('UTC:',dt_txt_UTC,'Tide:',tide_str)\n",
    "#             print('\\tOffset: ',(offset_h_dt_oj.seconds)/3600+(offset_h_dt_oj.days)*24,'from local:',local_zone)\n",
    "    \n",
    "            # Convert to Perth (+08)\n",
    "            # zone_AEDT = 11\n",
    "            # zone_Perth = 8\n",
    "            # offset_h = zone_Perth-zone_AEDT\n",
    "            # offset_h_dt_oj = timedelta(hours = offset_h)\n",
    "            # dt_obj_perth = dt_obj_AEDT + offset_h_dt_oj\n",
    "            # dt_txt_perth = dt_obj_perth.strftime(dt_format2)\n",
    "            # print ('Perth:',dt_txt_perth,'Tide:',tide_str)\n",
    "            # print('\\tOffset: ',(offset_h_dt_oj.seconds)/3600+(offset_h_dt_oj.days)*24,'from AEDT:',zone_AEDT)\n",
    "    \n",
    "            line = dt_txt_UTC\n",
    "            Y = line[:4]\n",
    "            M = line[5:7]\n",
    "            D = line[8:10]\n",
    "            h = line[11:13]\n",
    "            m = line[14:16]\n",
    "            s = line[17:19]\n",
    "            tide = tide_str\n",
    "            new_msg = (f'{Y}/{M}/{D} {h}:{m}:{s}.000 {tide}0000\\n')\n",
    "#             print(new_msg)\n",
    "            oFile_w.write(new_msg)\n",
    "    oFile_w.close()\n",
    "\n",
    "from pathlib import Path\n",
    "tide_data = r'D:\\OneDrive - Curtin University of Technology Australia\\write\\c3_vU\\Observed_Tide\\S1_201410'\n",
    "all_IN = [f for f in Path(tide_data).iterdir() if f.name.endswith('.csv')]\n",
    "for inFile_p in all_IN:\n",
    "    name = inFile_p.name.split('.')[0]\n",
    "    oFile_p = Path(tide_data) / (Path(tide_data).name + '_Observed_UTC_merge.tide')\n",
    "    print(inFile_p,'\\n',oFile_p)\n",
    "    LOCAL2UTC_tide(inFile_p,oFile_p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 S2_201509"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.a Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "from pathlib import Path\n",
    "#input directories\n",
    "indir = r'D:\\OneDrive - Curtin University of Technology Australia\\write\\c3_vU\\Observed_Tide\\S2_201509'\n",
    "#input settings\n",
    "in_delimiter = ','\n",
    "in_Ext = '.AST'\n",
    "#Output settings\n",
    "out_header = 'N'\n",
    "out_delimiter = in_delimiter\n",
    "out_colNames=['Day','Time','Tide','unknown','unknown']\n",
    "out_Ext = '.csv'\n",
    "out_fname = Path(indir) / (Path(indir).name + '_Observed_AWST_merge' + out_Ext)\n",
    "colNames = str(out_colNames)[1:-2].replace(\"'\",\"\").replace(', ',out_delimiter)\n",
    "#Write header based on user input choice\n",
    "outfile = open(out_fname,'w')\n",
    "if out_header == 'Y':\n",
    "        outfile.write(colNames+'\\n')\n",
    "else: pass\n",
    "#Merging text files using pure Python\n",
    "all_In = [f.absolute() for f in Path(indir).iterdir() if f.name.endswith(in_Ext) ]\n",
    "\n",
    "for fname in all_In:\n",
    "    if fname != out_fname:\n",
    "        with open(fname,'r') as infile:\n",
    "            for line in infile:\n",
    "                line = line.replace(in_delimiter,out_delimiter)\n",
    "                if line != '\\n': \n",
    "                    outfile.write(line)\n",
    "#                     print(line)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.b Local2Utc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\OneDrive - Curtin University of Technology Australia\\write\\c3_vU\\Observed_Tide\\S2_201509\\S2_201509_Observed_AWST_merge.csv \n",
      " D:\\OneDrive - Curtin University of Technology Australia\\write\\c3_vU\\Observed_Tide\\S2_201509\\S2_201509_Observed_UTC_merge.tide\n"
     ]
    }
   ],
   "source": [
    "def LOCAL2UTC_tide(inFile_p,oFile_p):\n",
    "    import os\n",
    "    import sys\n",
    "    from datetime import datetime\n",
    "    from datetime import timedelta\n",
    "    \n",
    "    dt_format1 = \"%Y-%m-%d %H:%M:%S\"\n",
    "    dt_format2 = \"%Y-%m-%d %H:%M:%S %Z%z\"\n",
    "    dt_format3 = \"%d/%m/%Y%H:%M\"\n",
    "    dt_format4 = \"%d/%m/%Y %H:%M\"\n",
    "    dt_format5 = \"%Y-%m-%d %H:%M:%S.000\"\n",
    "    dt_format6_DoTWA = \"%d/%m/%Y,%H:%M:%S\"\n",
    "    \n",
    "    \n",
    "    oFile_w = open(oFile_p,'w')\n",
    "    skip = 0\n",
    "    \n",
    "    with open(inFile_p,'r') as infile:\n",
    "        msg = '--------\\n'\n",
    "        oFile_w.write(msg)\n",
    "        for counter,line in enumerate(infile):\n",
    "            if counter < skip: continue\n",
    "            # if counter < 15:\n",
    "            line = line.strip('\\n')\n",
    "            line_list = line.split(',')\n",
    "            line_list2 = []\n",
    "            for l in line_list: line_list2.append(l.strip(' '))\n",
    "            tide_str = float(line_list2[2])\n",
    "            tide_str = f'{tide_str:.3f}'\n",
    "            dt_str = line_list2[0] + ',' + line_list2[1]\n",
    "            dt_obj_local = datetime.strptime(dt_str, dt_format6_DoTWA)\n",
    "            dt_txt_local = dt_obj_local.strftime(dt_format2)\n",
    "#             print ('Local:',dt_txt_local,'Tide:',tide_str)\n",
    "            \n",
    "            # Convert to UTC (+00)\n",
    "            local_zone = 8\n",
    "            offset_h = -local_zone\n",
    "            offset_h_dt_oj = timedelta(hours = offset_h)\n",
    "            dt_obj_UTC = dt_obj_local + offset_h_dt_oj\n",
    "            dt_txt_UTC = dt_obj_UTC.strftime(dt_format2)\n",
    "#             print ('UTC:',dt_txt_UTC,'Tide:',tide_str)\n",
    "#             print('\\tOffset: ',(offset_h_dt_oj.seconds)/3600+(offset_h_dt_oj.days)*24,'from local:',local_zone)\n",
    "    \n",
    "            # Convert to Perth (+08)\n",
    "            # zone_AEDT = 11\n",
    "            # zone_Perth = 8\n",
    "            # offset_h = zone_Perth-zone_AEDT\n",
    "            # offset_h_dt_oj = timedelta(hours = offset_h)\n",
    "            # dt_obj_perth = dt_obj_AEDT + offset_h_dt_oj\n",
    "            # dt_txt_perth = dt_obj_perth.strftime(dt_format2)\n",
    "            # print ('Perth:',dt_txt_perth,'Tide:',tide_str)\n",
    "            # print('\\tOffset: ',(offset_h_dt_oj.seconds)/3600+(offset_h_dt_oj.days)*24,'from AEDT:',zone_AEDT)\n",
    "    \n",
    "            line = dt_txt_UTC\n",
    "            Y = line[:4]\n",
    "            M = line[5:7]\n",
    "            D = line[8:10]\n",
    "            h = line[11:13]\n",
    "            m = line[14:16]\n",
    "            s = line[17:19]\n",
    "            tide = tide_str\n",
    "            new_msg = (f'{Y}/{M}/{D} {h}:{m}:{s}.000 {tide}0000\\n')\n",
    "#             print(new_msg)\n",
    "            oFile_w.write(new_msg)\n",
    "    oFile_w.close()\n",
    "\n",
    "from pathlib import Path\n",
    "tide_data = r'D:\\OneDrive - Curtin University of Technology Australia\\write\\c3_vU\\Observed_Tide\\S2_201509'\n",
    "all_IN = [f for f in Path(tide_data).iterdir() if f.name.endswith('.csv')]\n",
    "for inFile_p in all_IN:\n",
    "    name = inFile_p.name.split('.')[0]\n",
    "    oFile_p = Path(tide_data) / (Path(tide_data).name + '_Observed_UTC_merge.tide')\n",
    "    print(inFile_p,'\\n',oFile_p)\n",
    "    LOCAL2UTC_tide(inFile_p,oFile_p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 S3_201710"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.a Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "from pathlib import Path\n",
    "#input directories\n",
    "indir = r'D:\\OneDrive - Curtin University of Technology Australia\\write\\c3_vU\\Observed_Tide\\S3_201710'\n",
    "#input settings\n",
    "in_delimiter = ','\n",
    "in_Ext = '.txt'\n",
    "#Output settings\n",
    "out_header = 'N'\n",
    "out_delimiter = in_delimiter\n",
    "out_colNames=['Day','Time','Tide','unknown','unknown']\n",
    "out_Ext = '.csv'\n",
    "out_fname = Path(indir) / (Path(indir).name + '_Observed_AWST_merge' + out_Ext)\n",
    "colNames = str(out_colNames)[1:-2].replace(\"'\",\"\").replace(', ',out_delimiter)\n",
    "#Write header based on user input choice\n",
    "outfile = open(out_fname,'w')\n",
    "if out_header == 'Y':\n",
    "        outfile.write(colNames+'\\n')\n",
    "else: pass\n",
    "#Merging text files using pure Python\n",
    "all_In = [f.absolute() for f in Path(indir).iterdir() if f.name.endswith(in_Ext) ]\n",
    "\n",
    "skip_line = 4\n",
    "\n",
    "for fname in all_In:\n",
    "    if fname != out_fname:\n",
    "        with open(fname,'r') as infile:\n",
    "            for lineNo,line in enumerate(infile):\n",
    "                if lineNo >= skip_line:\n",
    "                    line = line.replace(in_delimiter,out_delimiter)\n",
    "                    if line != '\\n': \n",
    "                        outfile.write(line)\n",
    "    #                     print(line)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.b Local 2 UTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\OneDrive - Curtin University of Technology Australia\\write\\c3_vU\\Observed_Tide\\S3_201710\\S3_201710_Observed_AWST_merge.csv \n",
      " D:\\OneDrive - Curtin University of Technology Australia\\write\\c3_vU\\Observed_Tide\\S3_201710\\S3_201710_Observed_UTC_merge.tide\n"
     ]
    }
   ],
   "source": [
    "def LOCAL2UTC_tide(inFile_p,oFile_p):\n",
    "    import os\n",
    "    import sys\n",
    "    from datetime import datetime\n",
    "    from datetime import timedelta\n",
    "    \n",
    "    dt_format1 = \"%Y-%m-%d %H:%M:%S\"\n",
    "    dt_format2 = \"%Y-%m-%d %H:%M:%S %Z%z\"\n",
    "    dt_format3 = \"%d/%m/%Y%H:%M\"\n",
    "    dt_format4 = \"%d/%m/%Y %H:%M\"\n",
    "    dt_format5 = \"%Y-%m-%d %H:%M:%S.000\"\n",
    "    dt_format6_DoTWA = \"%d/%m/%Y,%H:%M:%S\"\n",
    "    dt_format6_DoTWA2 = \"%d/%m/%Y %H:%M\"\n",
    "    \n",
    "    \n",
    "    oFile_w = open(oFile_p,'w')\n",
    "    skip = 0\n",
    "    \n",
    "    with open(inFile_p,'r') as infile:\n",
    "        msg = '--------\\n'\n",
    "        oFile_w.write(msg)\n",
    "        for counter,line in enumerate(infile):\n",
    "            if counter < skip: continue\n",
    "            # if counter < 15:\n",
    "            line = line.strip('\\n')\n",
    "            line_list = line.split(',')\n",
    "            line_list2 = []\n",
    "            for l in line_list: line_list2.append(l.strip(' '))\n",
    "            tide_str = float(line_list2[1])\n",
    "            tide_str = f'{tide_str:.3f}'\n",
    "            dt_str = line_list2[0]\n",
    "            dt_obj_local = datetime.strptime(dt_str, dt_format6_DoTWA2)\n",
    "            dt_txt_local = dt_obj_local.strftime(dt_format2)\n",
    "#             print ('Local:',dt_txt_local,'Tide:',tide_str)\n",
    "            \n",
    "            # Convert to UTC (+00)\n",
    "            local_zone = 8\n",
    "            offset_h = -local_zone\n",
    "            offset_h_dt_oj = timedelta(hours = offset_h)\n",
    "            dt_obj_UTC = dt_obj_local + offset_h_dt_oj\n",
    "            dt_txt_UTC = dt_obj_UTC.strftime(dt_format2)\n",
    "#             print ('UTC:',dt_txt_UTC,'Tide:',tide_str)\n",
    "#             print('\\tOffset: ',(offset_h_dt_oj.seconds)/3600+(offset_h_dt_oj.days)*24,'from local:',local_zone)\n",
    "    \n",
    "            # Convert to Perth (+08)\n",
    "            # zone_AEDT = 11\n",
    "            # zone_Perth = 8\n",
    "            # offset_h = zone_Perth-zone_AEDT\n",
    "            # offset_h_dt_oj = timedelta(hours = offset_h)\n",
    "            # dt_obj_perth = dt_obj_AEDT + offset_h_dt_oj\n",
    "            # dt_txt_perth = dt_obj_perth.strftime(dt_format2)\n",
    "            # print ('Perth:',dt_txt_perth,'Tide:',tide_str)\n",
    "            # print('\\tOffset: ',(offset_h_dt_oj.seconds)/3600+(offset_h_dt_oj.days)*24,'from AEDT:',zone_AEDT)\n",
    "    \n",
    "            line = dt_txt_UTC\n",
    "            Y = line[:4]\n",
    "            M = line[5:7]\n",
    "            D = line[8:10]\n",
    "            h = line[11:13]\n",
    "            m = line[14:16]\n",
    "            s = line[17:19]\n",
    "            tide = tide_str\n",
    "            new_msg = (f'{Y}/{M}/{D} {h}:{m}:{s}.000 {tide}0000\\n')\n",
    "#             print(new_msg)\n",
    "            oFile_w.write(new_msg)\n",
    "    oFile_w.close()\n",
    "\n",
    "from pathlib import Path\n",
    "tide_data = r'D:\\OneDrive - Curtin University of Technology Australia\\write\\c3_vU\\Observed_Tide\\S3_201710'\n",
    "all_IN = [f for f in Path(tide_data).iterdir() if f.name.endswith('.csv')]\n",
    "for inFile_p in all_IN:\n",
    "    name = inFile_p.name.split('.')[0]\n",
    "    oFile_p = Path(tide_data) / (Path(tide_data).name + '_Observed_UTC_merge.tide')\n",
    "    print(inFile_p,'\\n',oFile_p)\n",
    "    LOCAL2UTC_tide(inFile_p,oFile_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 S4_201810"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.a Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "from pathlib import Path\n",
    "#input directories\n",
    "indir = r'D:\\OneDrive - Curtin University of Technology Australia\\write\\c3_vU\\Observed_Tide\\S4_201810'\n",
    "#input settings\n",
    "in_delimiter = ','\n",
    "in_Ext = '.txt'\n",
    "#Output settings\n",
    "out_header = 'N'\n",
    "out_delimiter = in_delimiter\n",
    "out_colNames=['Day','Time','Tide','unknown','unknown']\n",
    "out_Ext = '.csv'\n",
    "out_fname = Path(indir) / (Path(indir).name + '_Observed_AWST_merge' + out_Ext)\n",
    "colNames = str(out_colNames)[1:-2].replace(\"'\",\"\").replace(', ',out_delimiter)\n",
    "#Write header based on user input choice\n",
    "outfile = open(out_fname,'w')\n",
    "if out_header == 'Y':\n",
    "        outfile.write(colNames+'\\n')\n",
    "else: pass\n",
    "#Merging text files using pure Python\n",
    "all_In = [f.absolute() for f in Path(indir).iterdir() if f.name.endswith(in_Ext) ]\n",
    "\n",
    "skip_line = 1\n",
    "\n",
    "for fname in all_In:\n",
    "    if fname != out_fname:\n",
    "        with open(fname,'r') as infile:\n",
    "            for lineNo,line in enumerate(infile):\n",
    "                if lineNo >= skip_line:\n",
    "                    line = line.replace(in_delimiter,out_delimiter)\n",
    "                    if line != '\\n': \n",
    "                        outfile.write(line)\n",
    "    #                     print(line)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.b Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\OneDrive - Curtin University of Technology Australia\\write\\c3_vU\\Observed_Tide\\S4_201810\\S4_201810_Observed_AWST_merge.csv \n",
      " D:\\OneDrive - Curtin University of Technology Australia\\write\\c3_vU\\Observed_Tide\\S4_201810\\S4_201810_Observed_UTC_merge.tide\n"
     ]
    }
   ],
   "source": [
    "def LOCAL2UTC_tide(inFile_p,oFile_p):\n",
    "    import os\n",
    "    import sys\n",
    "    from datetime import datetime\n",
    "    from datetime import timedelta\n",
    "    \n",
    "    dt_format1 = \"%Y-%m-%d %H:%M:%S\"\n",
    "    dt_format2 = \"%Y-%m-%d %H:%M:%S %Z%z\"\n",
    "    dt_format3 = \"%d/%m/%Y%H:%M\"\n",
    "    dt_format4 = \"%d/%m/%Y %H:%M\"\n",
    "    dt_format5 = \"%Y-%m-%d %H:%M:%S.000\"\n",
    "    dt_format6_DoTWA = \"%d/%m/%Y,%H:%M:%S\"\n",
    "    dt_format6_DoTWA2 = '%Y-%m-%dT%H%M'\n",
    "    \n",
    "    oFile_w = open(oFile_p,'w')\n",
    "    skip = 0\n",
    "    \n",
    "    with open(inFile_p,'r') as infile:\n",
    "        msg = '--------\\n'\n",
    "        oFile_w.write(msg)\n",
    "        for counter,line in enumerate(infile):\n",
    "            if counter < skip: continue\n",
    "            # if counter < 15:\n",
    "            line = line.strip('\\n')\n",
    "            line_list = line.split(',')\n",
    "            line_list2 = []\n",
    "            for l in line_list: line_list2.append(l.strip(' '))\n",
    "            tide_str = float(line_list2[1])\n",
    "            tide_str = f'{tide_str:.3f}'\n",
    "            dt_str = line_list2[0].split(':')[0]+line_list2[0].split(':')[1]\n",
    "            dt_obj_local = datetime.strptime(dt_str, dt_format6_DoTWA2)\n",
    "            dt_txt_local = dt_obj_local.strftime(dt_format2)\n",
    "#             print ('Local:',dt_txt_local,'Tide:',tide_str)\n",
    "            \n",
    "            # Convert to UTC (+00)\n",
    "            local_zone = 8\n",
    "            offset_h = -local_zone\n",
    "            offset_h_dt_oj = timedelta(hours = offset_h)\n",
    "            dt_obj_UTC = dt_obj_local + offset_h_dt_oj\n",
    "            dt_txt_UTC = dt_obj_UTC.strftime(dt_format2)\n",
    "#             print ('UTC:',dt_txt_UTC,'Tide:',tide_str)\n",
    "#             print('\\tOffset: ',(offset_h_dt_oj.seconds)/3600+(offset_h_dt_oj.days)*24,'from local:',local_zone)\n",
    "    \n",
    "            # Convert to Perth (+08)\n",
    "            # zone_AEDT = 11\n",
    "            # zone_Perth = 8\n",
    "            # offset_h = zone_Perth-zone_AEDT\n",
    "            # offset_h_dt_oj = timedelta(hours = offset_h)\n",
    "            # dt_obj_perth = dt_obj_AEDT + offset_h_dt_oj\n",
    "            # dt_txt_perth = dt_obj_perth.strftime(dt_format2)\n",
    "            # print ('Perth:',dt_txt_perth,'Tide:',tide_str)\n",
    "            # print('\\tOffset: ',(offset_h_dt_oj.seconds)/3600+(offset_h_dt_oj.days)*24,'from AEDT:',zone_AEDT)\n",
    "    \n",
    "            line = dt_txt_UTC\n",
    "            Y = line[:4]\n",
    "            M = line[5:7]\n",
    "            D = line[8:10]\n",
    "            h = line[11:13]\n",
    "            m = line[14:16]\n",
    "            s = line[17:19]\n",
    "            tide = tide_str\n",
    "            new_msg = (f'{Y}/{M}/{D} {h}:{m}:{s}.000 {tide}0000\\n')\n",
    "#             print(new_msg)\n",
    "            oFile_w.write(new_msg)\n",
    "    oFile_w.close()\n",
    "\n",
    "from pathlib import Path\n",
    "tide_data = r'D:\\OneDrive - Curtin University of Technology Australia\\write\\c3_vU\\Observed_Tide\\S4_201810'\n",
    "all_IN = [f for f in Path(tide_data).iterdir() if f.name.endswith('.csv')]\n",
    "for inFile_p in all_IN:\n",
    "    name = inFile_p.name.split('.')[0]\n",
    "    oFile_p = Path(tide_data) / (Path(tide_data).name + '_Observed_UTC_merge.tide')\n",
    "    print(inFile_p,'\\n',oFile_p)\n",
    "    LOCAL2UTC_tide(inFile_p,oFile_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. S5_201904"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.a Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "from pathlib import Path\n",
    "#input directories\n",
    "indir = r'D:\\OneDrive - Curtin University of Technology Australia\\write\\c3_vU\\Observed_Tide\\S5_201904'\n",
    "#input settings\n",
    "in_delimiter = ','\n",
    "in_Ext = '.prn'\n",
    "#Output settings\n",
    "out_header = 'N'\n",
    "out_delimiter = in_delimiter\n",
    "out_colNames=['Day','Time','Tide','unknown','unknown']\n",
    "out_Ext = '.csv'\n",
    "out_fname = Path(indir) / (Path(indir).name + '_Observed_AWST_merge' + out_Ext)\n",
    "colNames = str(out_colNames)[1:-2].replace(\"'\",\"\").replace(', ',out_delimiter)\n",
    "#Write header based on user input choice\n",
    "outfile = open(out_fname,'w')\n",
    "if out_header == 'Y':\n",
    "        outfile.write(colNames+'\\n')\n",
    "else: pass\n",
    "#Merging text files using pure Python\n",
    "all_In = [f.absolute() for f in Path(indir).iterdir() if f.name.endswith(in_Ext) ]\n",
    "\n",
    "skip_line = 0\n",
    "\n",
    "for fname in all_In:\n",
    "    if fname != out_fname:\n",
    "        with open(fname,'r') as infile:\n",
    "            for lineNo,line in enumerate(infile):\n",
    "                if lineNo >= skip_line:\n",
    "                    line = line.replace(in_delimiter,out_delimiter)\n",
    "                    if line != '\\n': \n",
    "                        outfile.write(line)\n",
    "    #                     print(line)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.b Local 2 UTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\OneDrive - Curtin University of Technology Australia\\write\\c3_vU\\Observed_Tide\\S5_201904\\S5_201904_Observed_AWST_merge.csv \n",
      " D:\\OneDrive - Curtin University of Technology Australia\\write\\c3_vU\\Observed_Tide\\S5_201904\\S5_201904_Observed_UTC_merge.tide\n"
     ]
    }
   ],
   "source": [
    "def LOCAL2UTC_tide(inFile_p,oFile_p):\n",
    "    import os\n",
    "    import sys\n",
    "    from datetime import datetime\n",
    "    from datetime import timedelta\n",
    "    \n",
    "    dt_format1 = \"%Y-%m-%d %H:%M:%S\"\n",
    "    dt_format2 = \"%Y-%m-%d %H:%M:%S %Z%z\"\n",
    "    dt_format3 = \"%d/%m/%Y%H:%M\"\n",
    "    dt_format4 = \"%d/%m/%Y %H:%M\"\n",
    "    dt_format5 = \"%Y-%m-%d %H:%M:%S.000\"\n",
    "    dt_format6_DoTWA = \"%d/%m/%Y,%H:%M:%S\"\n",
    "    dt_format6_DoTWA3 = \"%Y-%m-%d,%H:%M:%S\"\n",
    "    \n",
    "    oFile_w = open(oFile_p,'w')\n",
    "    skip = 0\n",
    "    \n",
    "    with open(inFile_p,'r') as infile:\n",
    "        msg = '--------\\n'\n",
    "        oFile_w.write(msg)\n",
    "        for counter,line in enumerate(infile):\n",
    "            if counter < skip: continue\n",
    "            # if counter < 15:\n",
    "            line = line.strip('\\n')\n",
    "            line_list = line.split(',')\n",
    "            line_list2 = []\n",
    "            for l in line_list: line_list2.append(l.strip(' '))\n",
    "            tide_str = float(line_list2[2])\n",
    "            tide_str = f'{tide_str:.3f}'\n",
    "            dt_str = line_list2[0] + ',' + line_list2[1]\n",
    "            dt_obj_local = datetime.strptime(dt_str, dt_format6_DoTWA3)\n",
    "            dt_txt_local = dt_obj_local.strftime(dt_format2)\n",
    "#             print ('Local:',dt_txt_local,'Tide:',tide_str)\n",
    "            \n",
    "            # Convert to UTC (+00)\n",
    "            local_zone = 8\n",
    "            offset_h = -local_zone\n",
    "            offset_h_dt_oj = timedelta(hours = offset_h)\n",
    "            dt_obj_UTC = dt_obj_local + offset_h_dt_oj\n",
    "            dt_txt_UTC = dt_obj_UTC.strftime(dt_format2)\n",
    "#             print ('UTC:',dt_txt_UTC,'Tide:',tide_str)\n",
    "#             print('\\tOffset: ',(offset_h_dt_oj.seconds)/3600+(offset_h_dt_oj.days)*24,'from local:',local_zone)\n",
    "    \n",
    "            # Convert to Perth (+08)\n",
    "            # zone_AEDT = 11\n",
    "            # zone_Perth = 8\n",
    "            # offset_h = zone_Perth-zone_AEDT\n",
    "            # offset_h_dt_oj = timedelta(hours = offset_h)\n",
    "            # dt_obj_perth = dt_obj_AEDT + offset_h_dt_oj\n",
    "            # dt_txt_perth = dt_obj_perth.strftime(dt_format2)\n",
    "            # print ('Perth:',dt_txt_perth,'Tide:',tide_str)\n",
    "            # print('\\tOffset: ',(offset_h_dt_oj.seconds)/3600+(offset_h_dt_oj.days)*24,'from AEDT:',zone_AEDT)\n",
    "    \n",
    "            line = dt_txt_UTC\n",
    "            Y = line[:4]\n",
    "            M = line[5:7]\n",
    "            D = line[8:10]\n",
    "            h = line[11:13]\n",
    "            m = line[14:16]\n",
    "            s = line[17:19]\n",
    "            tide = tide_str\n",
    "            new_msg = (f'{Y}/{M}/{D} {h}:{m}:{s}.000 {tide}0000\\n')\n",
    "#             print(new_msg)\n",
    "            oFile_w.write(new_msg)\n",
    "    oFile_w.close()\n",
    "\n",
    "from pathlib import Path\n",
    "tide_data = r'D:\\OneDrive - Curtin University of Technology Australia\\write\\c3_vU\\Observed_Tide\\S5_201904'\n",
    "all_IN = [f for f in Path(tide_data).iterdir() if f.name.endswith('.csv')]\n",
    "for inFile_p in all_IN:\n",
    "    name = inFile_p.name.split('.')[0]\n",
    "    oFile_p = Path(tide_data) / (Path(tide_data).name + '_Observed_UTC_merge.tide')\n",
    "    print(inFile_p,'\\n',oFile_p)\n",
    "    LOCAL2UTC_tide(inFile_p,oFile_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6. S6_201911"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6.a Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "from pathlib import Path\n",
    "#input directories\n",
    "indir = r'D:\\OneDrive - Curtin University of Technology Australia\\write\\c3_vU\\Observed_Tide\\S6_201911'\n",
    "#input settings\n",
    "in_delimiter = ','\n",
    "in_Ext = '.txt'\n",
    "#Output settings\n",
    "out_header = 'N'\n",
    "out_delimiter = in_delimiter\n",
    "out_colNames=['Day','Time','Tide','unknown','unknown']\n",
    "out_Ext = '.csv'\n",
    "out_fname = Path(indir) / (Path(indir).name + '_Observed_AWST_merge' + out_Ext)\n",
    "colNames = str(out_colNames)[1:-2].replace(\"'\",\"\").replace(', ',out_delimiter)\n",
    "#Write header based on user input choice\n",
    "outfile = open(out_fname,'w')\n",
    "if out_header == 'Y':\n",
    "        outfile.write(colNames+'\\n')\n",
    "else: pass\n",
    "#Merging text files using pure Python\n",
    "all_In = [f.absolute() for f in Path(indir).iterdir() if f.name.endswith(in_Ext) ]\n",
    "\n",
    "skip_line = 2\n",
    "\n",
    "for fname in all_In:\n",
    "    if fname != out_fname:\n",
    "        with open(fname,'r') as infile:\n",
    "            for lineNo,line in enumerate(infile):\n",
    "                if lineNo >= skip_line:\n",
    "                    line = line.replace(in_delimiter,out_delimiter)\n",
    "                    if line != '\\n': \n",
    "                        outfile.write(line)\n",
    "    #                     print(line)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6.b Local 2 Utc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\OneDrive - Curtin University of Technology Australia\\write\\c3_vU\\Observed_Tide\\S6_201911\\S6_201911_Observed_AWST_merge.csv \n",
      " D:\\OneDrive - Curtin University of Technology Australia\\write\\c3_vU\\Observed_Tide\\S6_201911\\S6_201911_Observed_UTC_merge.tide\n"
     ]
    }
   ],
   "source": [
    "def LOCAL2UTC_tide(inFile_p,oFile_p):\n",
    "    import os\n",
    "    import sys\n",
    "    from datetime import datetime\n",
    "    from datetime import timedelta\n",
    "    \n",
    "    dt_format1 = \"%Y-%m-%d %H:%M:%S\"\n",
    "    dt_format2 = \"%Y-%m-%d %H:%M:%S %Z%z\"\n",
    "    dt_format3 = \"%d/%m/%Y%H:%M\"\n",
    "    dt_format4 = \"%d/%m/%Y %H:%M\"\n",
    "    dt_format5 = \"%Y-%m-%d %H:%M:%S.000\"\n",
    "    dt_format6_DoTWA = \"%d/%m/%Y,%H:%M:%S\"\n",
    "    dt_format6_DoTWA3 = \"%Y-%m-%d,%H:%M:%S\"\n",
    "    dt_format6_DoTWA4 = '%Y-%m-%dT%H:%M:%S+08:00'\n",
    "    oFile_w = open(oFile_p,'w')\n",
    "    skip = 0\n",
    "    \n",
    "    with open(inFile_p,'r') as infile:\n",
    "        msg = '--------\\n'\n",
    "        oFile_w.write(msg)\n",
    "        for counter,line in enumerate(infile):\n",
    "            if counter < skip: continue\n",
    "            # if counter < 15:\n",
    "            line = line.strip('\\n')\n",
    "            line_list = line.split(',')\n",
    "            line_list2 = []\n",
    "            for l in line_list: line_list2.append(l.strip(' '))\n",
    "            tide_str = float(line_list2[1])\n",
    "            tide_str = f'{tide_str:.3f}'\n",
    "            dt_str = line_list2[0]\n",
    "            dt_obj_local = datetime.strptime(dt_str, dt_format4)\n",
    "            dt_txt_local = dt_obj_local.strftime(dt_format2)\n",
    "#             print ('Local:',dt_txt_local,'Tide:',tide_str)\n",
    "            \n",
    "            # Convert to UTC (+00)\n",
    "            local_zone = 8\n",
    "            offset_h = -local_zone\n",
    "            offset_h_dt_oj = timedelta(hours = offset_h)\n",
    "            dt_obj_UTC = dt_obj_local + offset_h_dt_oj\n",
    "            dt_txt_UTC = dt_obj_UTC.strftime(dt_format2)\n",
    "#             print ('UTC:',dt_txt_UTC,'Tide:',tide_str)\n",
    "#             print('\\tOffset: ',(offset_h_dt_oj.seconds)/3600+(offset_h_dt_oj.days)*24,'from local:',local_zone)\n",
    "    \n",
    "            # Convert to Perth (+08)\n",
    "            # zone_AEDT = 11\n",
    "            # zone_Perth = 8\n",
    "            # offset_h = zone_Perth-zone_AEDT\n",
    "            # offset_h_dt_oj = timedelta(hours = offset_h)\n",
    "            # dt_obj_perth = dt_obj_AEDT + offset_h_dt_oj\n",
    "            # dt_txt_perth = dt_obj_perth.strftime(dt_format2)\n",
    "            # print ('Perth:',dt_txt_perth,'Tide:',tide_str)\n",
    "            # print('\\tOffset: ',(offset_h_dt_oj.seconds)/3600+(offset_h_dt_oj.days)*24,'from AEDT:',zone_AEDT)\n",
    "    \n",
    "            line = dt_txt_UTC\n",
    "            Y = line[:4]\n",
    "            M = line[5:7]\n",
    "            D = line[8:10]\n",
    "            h = line[11:13]\n",
    "            m = line[14:16]\n",
    "            s = line[17:19]\n",
    "            tide = tide_str\n",
    "            new_msg = (f'{Y}/{M}/{D} {h}:{m}:{s}.000 {tide}0000\\n')\n",
    "#             print(new_msg)\n",
    "            oFile_w.write(new_msg)\n",
    "    oFile_w.close()\n",
    "\n",
    "from pathlib import Path\n",
    "tide_data = r'D:\\OneDrive - Curtin University of Technology Australia\\write\\c3_vU\\Observed_Tide\\S6_201911'\n",
    "all_IN = [f for f in Path(tide_data).iterdir() if f.name.endswith('.csv')]\n",
    "for inFile_p in all_IN:\n",
    "    name = inFile_p.name.split('.')[0]\n",
    "    oFile_p = Path(tide_data) / (Path(tide_data).name + '_Observed_UTC_merge.tide')\n",
    "    print(inFile_p,'\\n',oFile_p)\n",
    "    LOCAL2UTC_tide(inFile_p,oFile_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 S7_202004"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7.a Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "from pathlib import Path\n",
    "#input directories\n",
    "indir = r'D:\\OneDrive - Curtin University of Technology Australia\\write\\c3_vU\\Observed_Tide\\S7_202004'\n",
    "#input settings\n",
    "in_delimiter = ','\n",
    "in_Ext = '.txt'\n",
    "#Output settings\n",
    "out_header = 'N'\n",
    "out_delimiter = in_delimiter\n",
    "out_colNames=['Day','Time','Tide','unknown','unknown']\n",
    "out_Ext = '.csv'\n",
    "out_fname = Path(indir) / (Path(indir).name + '_Observed_AWST_merge' + out_Ext)\n",
    "colNames = str(out_colNames)[1:-2].replace(\"'\",\"\").replace(', ',out_delimiter)\n",
    "#Write header based on user input choice\n",
    "outfile = open(out_fname,'w')\n",
    "if out_header == 'Y':\n",
    "        outfile.write(colNames+'\\n')\n",
    "else: pass\n",
    "#Merging text files using pure Python\n",
    "all_In = [f.absolute() for f in Path(indir).iterdir() if f.name.endswith(in_Ext) ]\n",
    "\n",
    "skip_line = 2\n",
    "\n",
    "for fname in all_In:\n",
    "    if fname != out_fname:\n",
    "        with open(fname,'r') as infile:\n",
    "            for lineNo,line in enumerate(infile):\n",
    "                if lineNo >= skip_line:\n",
    "                    line = line.replace(in_delimiter,out_delimiter)\n",
    "                    if line != '\\n': \n",
    "                        outfile.write(line)\n",
    "    #                     print(line)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7.b Local 2 Utc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\OneDrive - Curtin University of Technology Australia\\write\\c3_vU\\Observed_Tide\\S7_202004\\S7_202004_Observed_AWST_merge.csv \n",
      " D:\\OneDrive - Curtin University of Technology Australia\\write\\c3_vU\\Observed_Tide\\S7_202004\\S7_202004_Observed_UTC_merge.tide\n"
     ]
    }
   ],
   "source": [
    "def LOCAL2UTC_tide(inFile_p,oFile_p):\n",
    "    import os\n",
    "    import sys\n",
    "    from datetime import datetime\n",
    "    from datetime import timedelta\n",
    "    \n",
    "    dt_format1 = \"%Y-%m-%d %H:%M:%S\"\n",
    "    dt_format2 = \"%Y-%m-%d %H:%M:%S %Z%z\"\n",
    "    dt_format3 = \"%d/%m/%Y%H:%M\"\n",
    "    dt_format4 = \"%d/%m/%Y %H:%M\"\n",
    "    dt_format5 = \"%Y-%m-%d %H:%M:%S.000\"\n",
    "    dt_format6_DoTWA = \"%d/%m/%Y,%H:%M:%S\"\n",
    "    dt_format6_DoTWA3 = \"%Y-%m-%d,%H:%M:%S\"\n",
    "    dt_format6_DoTWA4 = '%Y-%m-%dT%H:%M:%S+08:00'\n",
    "    oFile_w = open(oFile_p,'w')\n",
    "    skip = 0\n",
    "    \n",
    "    with open(inFile_p,'r') as infile:\n",
    "        msg = '--------\\n'\n",
    "        oFile_w.write(msg)\n",
    "        for counter,line in enumerate(infile):\n",
    "            if counter < skip: continue\n",
    "            # if counter < 15:\n",
    "            line = line.strip('\\n')\n",
    "            line_list = line.split(',')\n",
    "            line_list2 = []\n",
    "            for l in line_list: line_list2.append(l.strip(' '))\n",
    "            tide_str = float(line_list2[1])\n",
    "            tide_str = f'{tide_str:.3f}'\n",
    "            dt_str = line_list2[0]\n",
    "            dt_obj_local = datetime.strptime(dt_str, dt_format6_DoTWA4)\n",
    "            dt_txt_local = dt_obj_local.strftime(dt_format2)\n",
    "#             print ('Local:',dt_txt_local,'Tide:',tide_str)\n",
    "            \n",
    "            # Convert to UTC (+00)\n",
    "            local_zone = 8\n",
    "            offset_h = -local_zone\n",
    "            offset_h_dt_oj = timedelta(hours = offset_h)\n",
    "            dt_obj_UTC = dt_obj_local + offset_h_dt_oj\n",
    "            dt_txt_UTC = dt_obj_UTC.strftime(dt_format2)\n",
    "#             print ('UTC:',dt_txt_UTC,'Tide:',tide_str)\n",
    "#             print('\\tOffset: ',(offset_h_dt_oj.seconds)/3600+(offset_h_dt_oj.days)*24,'from local:',local_zone)\n",
    "    \n",
    "            # Convert to Perth (+08)\n",
    "            # zone_AEDT = 11\n",
    "            # zone_Perth = 8\n",
    "            # offset_h = zone_Perth-zone_AEDT\n",
    "            # offset_h_dt_oj = timedelta(hours = offset_h)\n",
    "            # dt_obj_perth = dt_obj_AEDT + offset_h_dt_oj\n",
    "            # dt_txt_perth = dt_obj_perth.strftime(dt_format2)\n",
    "            # print ('Perth:',dt_txt_perth,'Tide:',tide_str)\n",
    "            # print('\\tOffset: ',(offset_h_dt_oj.seconds)/3600+(offset_h_dt_oj.days)*24,'from AEDT:',zone_AEDT)\n",
    "    \n",
    "            line = dt_txt_UTC\n",
    "            Y = line[:4]\n",
    "            M = line[5:7]\n",
    "            D = line[8:10]\n",
    "            h = line[11:13]\n",
    "            m = line[14:16]\n",
    "            s = line[17:19]\n",
    "            tide = tide_str\n",
    "            new_msg = (f'{Y}/{M}/{D} {h}:{m}:{s}.000 {tide}0000\\n')\n",
    "#             print(new_msg)\n",
    "            oFile_w.write(new_msg)\n",
    "    oFile_w.close()\n",
    "\n",
    "from pathlib import Path\n",
    "tide_data = r'D:\\OneDrive - Curtin University of Technology Australia\\write\\c3_vU\\Observed_Tide\\S7_202004'\n",
    "all_IN = [f for f in Path(tide_data).iterdir() if f.name.endswith('.csv')]\n",
    "for inFile_p in all_IN:\n",
    "    name = inFile_p.name.split('.')[0]\n",
    "    oFile_p = Path(tide_data) / (Path(tide_data).name + '_Observed_UTC_merge.tide')\n",
    "    print(inFile_p,'\\n',oFile_p)\n",
    "    LOCAL2UTC_tide(inFile_p,oFile_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8 202002_Patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8.a Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "from pathlib import Path\n",
    "#input directories\n",
    "indir = r'D:\\DoTWA_Data\\202002_Patch\\fr20200212_port_beach\\Tide\\Export'\n",
    "#input settings\n",
    "in_delimiter = ','\n",
    "in_Ext = '.txt'\n",
    "#Output settings\n",
    "out_header = 'N'\n",
    "out_delimiter = in_delimiter\n",
    "out_colNames=['Day','Time','Tide','unknown','unknown']\n",
    "out_Ext = '.csv'\n",
    "out_fname = Path(indir) / (Path(indir).parent.parent.parent.name + '_Observed_AWST_merge' + out_Ext)\n",
    "colNames = str(out_colNames)[1:-2].replace(\"'\",\"\").replace(', ',out_delimiter)\n",
    "#Write header based on user input choice\n",
    "outfile = open(out_fname,'w')\n",
    "if out_header == 'Y':\n",
    "        outfile.write(colNames+'\\n')\n",
    "else: pass\n",
    "#Merging text files using pure Python\n",
    "all_In = [f.absolute() for f in Path(indir).iterdir() if f.name.endswith(in_Ext) ]\n",
    "\n",
    "skip_line = 5\n",
    "\n",
    "for fname in all_In:\n",
    "    if fname != out_fname:\n",
    "        with open(fname,'r') as infile:\n",
    "            for lineNo,line in enumerate(infile):\n",
    "                if lineNo >= skip_line:\n",
    "                    line = line.replace(in_delimiter,out_delimiter)\n",
    "                    if line != '\\n': \n",
    "                        outfile.write(line)\n",
    "    #                     print(line)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8.b Local time to UTC Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\DoTWA_Data\\202002_Patch\\fr20200212_port_beach\\Tide\\Export\\202002_Patch_Observed_AWST_merge.csv \n",
      " D:\\DoTWA_Data\\202002_Patch\\fr20200212_port_beach\\Tide\\Export\\202002_Patch_Observed_UTC_merge.tide\n"
     ]
    }
   ],
   "source": [
    "def LOCAL2UTC_tide(inFile_p,oFile_p):\n",
    "    import os\n",
    "    import sys\n",
    "    from datetime import datetime\n",
    "    from datetime import timedelta\n",
    "    \n",
    "    dt_format1 = \"%Y-%m-%d %H:%M:%S\"\n",
    "    dt_format2 = \"%Y-%m-%d %H:%M:%S %Z%z\"\n",
    "    dt_format2b = \"%Y-%m-%d %H:%M:%S.%f\"\n",
    "    dt_format3 = \"%d/%m/%Y%H:%M\"\n",
    "    dt_format4 = \"%d/%m/%Y %H:%M\"\n",
    "    dt_format5 = \"%Y-%m-%d %H:%M:%S.000\"\n",
    "    dt_format6 = \"%Y-%m-%d %H:%M:%S.%f\"\n",
    "    dt_format6_DoTWA = \"%d/%m/%Y,%H:%M:%S\"\n",
    "    dt_format6_DoTWA3 = \"%Y-%m-%d,%H:%M:%S\"\n",
    "    dt_format6_DoTWA4 = '%Y-%m-%dT%H:%M:%S+08:00'\n",
    "    oFile_w = open(oFile_p,'w')\n",
    "    skip = 0\n",
    "    \n",
    "    with open(inFile_p,'r') as infile:\n",
    "        msg = '--------\\n'\n",
    "        oFile_w.write(msg)\n",
    "        for counter,line in enumerate(infile):\n",
    "            if counter < skip: continue\n",
    "            # if counter < 15:\n",
    "            line = line.strip('\\n')\n",
    "            line_list = line.split(' ')\n",
    "            line_list2 = []\n",
    "            for l in line_list: line_list2.append(l.strip(' '))\n",
    "            tide_str = float(line_list2[2])\n",
    "            tide_str = f'{tide_str:.3f}'\n",
    "            dt_str = line_list2[0] +' '+line_list2[1]\n",
    "            dt_obj_local = datetime.strptime(dt_str, dt_format6)\n",
    "            dt_txt_local = dt_obj_local.strftime(dt_format2)\n",
    "#             print ('Local:',dt_txt_local,'Tide:',tide_str)\n",
    "            \n",
    "            # Convert to UTC (+00)\n",
    "            local_zone = 8\n",
    "            offset_h = -local_zone\n",
    "            offset_h_dt_oj = timedelta(hours = offset_h)\n",
    "            dt_obj_UTC = dt_obj_local + offset_h_dt_oj\n",
    "            dt_txt_UTC = dt_obj_UTC.strftime(dt_format2b)\n",
    "#             print ('UTC:',dt_txt_UTC,'Tide:',tide_str)\n",
    "#             print('\\tOffset: ',(offset_h_dt_oj.seconds)/3600+(offset_h_dt_oj.days)*24,'from local:',local_zone)\n",
    "    \n",
    "            # Convert to Perth (+08)\n",
    "            # zone_AEDT = 11\n",
    "            # zone_Perth = 8\n",
    "            # offset_h = zone_Perth-zone_AEDT\n",
    "            # offset_h_dt_oj = timedelta(hours = offset_h)\n",
    "            # dt_obj_perth = dt_obj_AEDT + offset_h_dt_oj\n",
    "            # dt_txt_perth = dt_obj_perth.strftime(dt_format2)\n",
    "            # print ('Perth:',dt_txt_perth,'Tide:',tide_str)\n",
    "            # print('\\tOffset: ',(offset_h_dt_oj.seconds)/3600+(offset_h_dt_oj.days)*24,'from AEDT:',zone_AEDT)\n",
    "    \n",
    "            line = dt_txt_UTC\n",
    "            Y = line[:4]\n",
    "            M = line[5:7]\n",
    "            D = line[8:10]\n",
    "            h = line[11:13]\n",
    "            m = line[14:16]\n",
    "            # s = line[17:19]\n",
    "            s = line[17:23]\n",
    "            tide = tide_str\n",
    "            # new_msg = (f'{Y}/{M}/{D} {h}:{m}:{s}.000 {tide}0000\\n')\n",
    "            new_msg = (f'{Y}/{M}/{D} {h}:{m}:{s} {tide}0000\\n')\n",
    "#             print(new_msg)\n",
    "            oFile_w.write(new_msg)\n",
    "    oFile_w.close()\n",
    "\n",
    "from pathlib import Path\n",
    "tide_data = r'D:\\DoTWA_Data\\202002_Patch\\fr20200212_port_beach\\Tide\\Export'\n",
    "all_IN = [f for f in Path(tide_data).iterdir() if f.name.endswith('.csv')]\n",
    "for inFile_p in all_IN:\n",
    "    name = inFile_p.name.split('.')[0]\n",
    "    oFile_p = Path(tide_data) / (Path(tide_data).parent.parent.parent.name + '_Observed_UTC_merge.tide')\n",
    "    print(inFile_p,'\\n',oFile_p)\n",
    "    LOCAL2UTC_tide(inFile_p,oFile_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.9 202003_Patch (PT3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.9.a Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "from pathlib import Path\n",
    "#input directories\n",
    "indir = r'D:\\DoTWA_Data\\202003_Patch\\FR20200319_pathTest\\Tide'\n",
    "#input settings\n",
    "in_delimiter = ','\n",
    "in_Ext = '.prn'\n",
    "#Output settings\n",
    "out_header = 'N'\n",
    "out_delimiter = in_delimiter\n",
    "out_colNames=['Day','Time','Tide','unknown','unknown']\n",
    "out_Ext = '.csv'\n",
    "out_fname = Path(indir) / (Path(indir).parent.parent.name + '_Observed_AWST_merge' + out_Ext)\n",
    "colNames = str(out_colNames)[1:-2].replace(\"'\",\"\").replace(', ',out_delimiter)\n",
    "#Write header based on user input choice\n",
    "outfile = open(out_fname,'w')\n",
    "if out_header == 'Y':\n",
    "        outfile.write(colNames+'\\n')\n",
    "else: pass\n",
    "#Merging text files using pure Python\n",
    "all_In = [f.absolute() for f in Path(indir).iterdir() if f.name.endswith(in_Ext) ]\n",
    "\n",
    "skip_line = 0\n",
    "\n",
    "for fname in all_In:\n",
    "    if fname != out_fname:\n",
    "        with open(fname,'r') as infile:\n",
    "            for lineNo,line in enumerate(infile):\n",
    "                if lineNo >= skip_line:\n",
    "                    line = line.replace(in_delimiter,out_delimiter)\n",
    "                    if line != '\\n': \n",
    "                        outfile.write(line)\n",
    "    #                     print(line)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.9.b Local time to UTC Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\DoTWA_Data\\202003_Patch\\FR20200319_pathTest\\Tide\\202003_Patch_Observed_AWST_merge.csv \n",
      " D:\\DoTWA_Data\\202003_Patch\\FR20200319_pathTest\\Tide\\202003_Patch_Observed_UTC_merge.tide\n"
     ]
    }
   ],
   "source": [
    "def LOCAL2UTC_tide(inFile_p,oFile_p):\n",
    "    import os\n",
    "    import sys\n",
    "    from datetime import datetime\n",
    "    from datetime import timedelta\n",
    "    \n",
    "    dt_format1 = \"%Y-%m-%d %H:%M:%S\"\n",
    "    dt_format2 = \"%Y-%m-%d %H:%M:%S %Z%z\"\n",
    "    dt_format2a = \"%Y-%m-%d %H:%M:%S\"\n",
    "    dt_format2b = \"%Y-%m-%d %H:%M:%S.%f\"\n",
    "    dt_format3 = \"%d/%m/%Y%H:%M\"\n",
    "    dt_format4 = \"%d/%m/%Y %H:%M\"\n",
    "    dt_format5 = \"%Y-%m-%d %H:%M:%S.000\"\n",
    "    dt_format6 = \"%Y-%m-%d %H:%M:%S.%f\"\n",
    "    dt_format6_DoTWA = \"%d/%m/%Y,%H:%M:%S\"\n",
    "    dt_format6_DoTWA3 = \"%Y-%m-%d,%H:%M:%S\"\n",
    "    dt_format6_DoTWA4 = '%Y-%m-%dT%H:%M:%S+08:00'\n",
    "    oFile_w = open(oFile_p,'w')\n",
    "    skip = 0\n",
    "    \n",
    "    with open(inFile_p,'r') as infile:\n",
    "        msg = '--------\\n'\n",
    "        oFile_w.write(msg)\n",
    "        for counter,line in enumerate(infile):\n",
    "            if counter < skip: continue\n",
    "            # if counter < 15:\n",
    "            line = line.strip('\\n')\n",
    "            # line_list = line.split(' ')\n",
    "            line_list = line.split(',')\n",
    "            line_list2 = []\n",
    "            for l in line_list: line_list2.append(l.strip(' ')) #strip the space in list element if it presents\n",
    "            tide_str = float(line_list2[2])\n",
    "            tide_str = f'{tide_str:.3f}'\n",
    "            dt_str = line_list2[0] +' '+line_list2[1]\n",
    "            dt_obj_local = datetime.strptime(dt_str, dt_format2a)\n",
    "            dt_txt_local = dt_obj_local.strftime(dt_format2)\n",
    "#             print ('Local:',dt_txt_local,'Tide:',tide_str)\n",
    "            \n",
    "            # Convert to UTC (+00)\n",
    "            local_zone = 8\n",
    "            offset_h = -local_zone\n",
    "            offset_h_dt_oj = timedelta(hours = offset_h)\n",
    "            dt_obj_UTC = dt_obj_local + offset_h_dt_oj\n",
    "            dt_txt_UTC = dt_obj_UTC.strftime(dt_format2)\n",
    "#             print ('UTC:',dt_txt_UTC,'Tide:',tide_str)\n",
    "#             print('\\tOffset: ',(offset_h_dt_oj.seconds)/3600+(offset_h_dt_oj.days)*24,'from local:',local_zone)\n",
    "    \n",
    "            # Convert to Perth (+08)\n",
    "            # zone_AEDT = 11\n",
    "            # zone_Perth = 8\n",
    "            # offset_h = zone_Perth-zone_AEDT\n",
    "            # offset_h_dt_oj = timedelta(hours = offset_h)\n",
    "            # dt_obj_perth = dt_obj_AEDT + offset_h_dt_oj\n",
    "            # dt_txt_perth = dt_obj_perth.strftime(dt_format2)\n",
    "            # print ('Perth:',dt_txt_perth,'Tide:',tide_str)\n",
    "            # print('\\tOffset: ',(offset_h_dt_oj.seconds)/3600+(offset_h_dt_oj.days)*24,'from AEDT:',zone_AEDT)\n",
    "    \n",
    "            line = dt_txt_UTC\n",
    "            Y = line[:4]\n",
    "            M = line[5:7]\n",
    "            D = line[8:10]\n",
    "            h = line[11:13]\n",
    "            m = line[14:16]\n",
    "            s = line[17:19]\n",
    "            # s = line[17:23]\n",
    "            tide = tide_str\n",
    "            new_msg = (f'{Y}/{M}/{D} {h}:{m}:{s}.000 {tide}0000\\n')\n",
    "#             new_msg = (f'{Y}/{M}/{D} {h}:{m}:{s} {tide}0000\\n')\n",
    "#             print(new_msg)\n",
    "            oFile_w.write(new_msg)\n",
    "    oFile_w.close()\n",
    "\n",
    "from pathlib import Path\n",
    "tide_data = r'D:\\DoTWA_Data\\202003_Patch\\FR20200319_pathTest\\Tide'\n",
    "all_IN = [f for f in Path(tide_data).iterdir() if f.name.endswith('.csv')]\n",
    "for inFile_p in all_IN:\n",
    "    name = inFile_p.name.split('.')[0]\n",
    "    oFile_p = Path(tide_data) / (Path(tide_data).parent.parent.name + '_Observed_UTC_merge.tide')\n",
    "    print(inFile_p,'\\n',oFile_p)\n",
    "    LOCAL2UTC_tide(inFile_p,oFile_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.10 202004_Patch (PT4) - The same as S7_202004"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.10.a Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.9.b Local time to UTC Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.11 202005_PatchTest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.11.a Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "from pathlib import Path\n",
    "#input directories\n",
    "indir = r'D:\\DoTWA_Data\\202005_Patch\\202005_PatchTest\\Export'\n",
    "#input settings\n",
    "in_delimiter = ','\n",
    "in_Ext = '.txt'\n",
    "#Output settings\n",
    "out_header = 'N'\n",
    "out_delimiter = in_delimiter\n",
    "out_colNames=['Day','Time','Tide','unknown','unknown']\n",
    "out_Ext = '.csv'\n",
    "out_fname = Path(indir) / (Path(indir).parent.name + '_Observed_AWST_merge' + out_Ext)\n",
    "colNames = str(out_colNames)[1:-2].replace(\"'\",\"\").replace(', ',out_delimiter)\n",
    "#Write header based on user input choice\n",
    "outfile = open(out_fname,'w')\n",
    "if out_header == 'Y':\n",
    "        outfile.write(colNames+'\\n')\n",
    "else: pass\n",
    "#Merging text files using pure Python\n",
    "all_In = [f.absolute() for f in Path(indir).iterdir() if f.name.endswith(in_Ext) ]\n",
    "\n",
    "skip_line = 5\n",
    "\n",
    "for fname in all_In:\n",
    "    if fname != out_fname:\n",
    "        with open(fname,'r') as infile:\n",
    "            for lineNo,line in enumerate(infile):\n",
    "                if lineNo >= skip_line:\n",
    "                    line = line.replace(in_delimiter,out_delimiter)\n",
    "                    if line != '\\n': \n",
    "                        outfile.write(line)\n",
    "    #                     print(line)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.9.b Local time to UTC Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\DoTWA_Data\\202005_Patch\\202005_PatchTest\\Export\\202005_PatchTest_Observed_AWST_merge.csv \n",
      " D:\\DoTWA_Data\\202005_Patch\\202005_PatchTest\\Export\\202005_PatchTest_Observed_UTC_merge.tide\n"
     ]
    }
   ],
   "source": [
    "def LOCAL2UTC_tide(inFile_p,oFile_p):\n",
    "    import os\n",
    "    import sys\n",
    "    from datetime import datetime\n",
    "    from datetime import timedelta\n",
    "    \n",
    "    dt_format1 = \"%Y-%m-%d %H:%M:%S\"\n",
    "    dt_format2 = \"%Y-%m-%d %H:%M:%S %Z%z\"\n",
    "    dt_format2a = \"%Y-%m-%d %H:%M:%S\"\n",
    "    dt_format2b = \"%Y-%m-%d %H:%M:%S.%f\"\n",
    "    dt_format3 = \"%d/%m/%Y%H:%M\"\n",
    "    dt_format4 = \"%d/%m/%Y %H:%M\"\n",
    "    dt_format5 = \"%Y-%m-%d %H:%M:%S.000\"\n",
    "    dt_format6 = \"%Y-%m-%d %H:%M:%S.%f\"\n",
    "    dt_format6_DoTWA = \"%d/%m/%Y,%H:%M:%S\"\n",
    "    dt_format6_DoTWA3 = \"%Y-%m-%d,%H:%M:%S\"\n",
    "    dt_format6_DoTWA4 = '%Y-%m-%dT%H:%M:%S+08:00'\n",
    "    oFile_w = open(oFile_p,'w')\n",
    "    skip = 0\n",
    "    \n",
    "    with open(inFile_p,'r') as infile:\n",
    "        msg = '--------\\n'\n",
    "        oFile_w.write(msg)\n",
    "        for counter,line in enumerate(infile):\n",
    "            if counter < skip: continue\n",
    "            # if counter < 15:\n",
    "            line = line.strip('\\n')\n",
    "            line_list = line.split(' ')\n",
    "            # line_list = line.split(',')\n",
    "            line_list2 = []\n",
    "            for l in line_list: line_list2.append(l.strip(' ')) #strip the space in list element if it presents\n",
    "            tide_str = float(line_list2[2])\n",
    "            tide_str = f'{tide_str:.3f}'\n",
    "            dt_str = line_list2[0] +' '+line_list2[1]\n",
    "            dt_obj_local = datetime.strptime(dt_str, dt_format6)\n",
    "            dt_txt_local = dt_obj_local.strftime(dt_format2b)\n",
    "#             print ('Local:',dt_txt_local,'Tide:',tide_str)\n",
    "            \n",
    "            # Convert to UTC (+00)\n",
    "            local_zone = 8\n",
    "            offset_h = -local_zone\n",
    "            offset_h_dt_oj = timedelta(hours = offset_h)\n",
    "            dt_obj_UTC = dt_obj_local + offset_h_dt_oj\n",
    "            dt_txt_UTC = dt_obj_UTC.strftime(dt_format2b)\n",
    "#             print ('UTC:',dt_txt_UTC,'Tide:',tide_str)\n",
    "#             print('\\tOffset: ',(offset_h_dt_oj.seconds)/3600+(offset_h_dt_oj.days)*24,'from local:',local_zone)\n",
    "    \n",
    "            # Convert to Perth (+08)\n",
    "            # zone_AEDT = 11\n",
    "            # zone_Perth = 8\n",
    "            # offset_h = zone_Perth-zone_AEDT\n",
    "            # offset_h_dt_oj = timedelta(hours = offset_h)\n",
    "            # dt_obj_perth = dt_obj_AEDT + offset_h_dt_oj\n",
    "            # dt_txt_perth = dt_obj_perth.strftime(dt_format2)\n",
    "            # print ('Perth:',dt_txt_perth,'Tide:',tide_str)\n",
    "            # print('\\tOffset: ',(offset_h_dt_oj.seconds)/3600+(offset_h_dt_oj.days)*24,'from AEDT:',zone_AEDT)\n",
    "    \n",
    "            line = dt_txt_UTC\n",
    "            Y = line[:4]\n",
    "            M = line[5:7]\n",
    "            D = line[8:10]\n",
    "            h = line[11:13]\n",
    "            m = line[14:16]\n",
    "            # s = line[17:19]\n",
    "            s = line[17:23]\n",
    "            tide = tide_str\n",
    "#             new_msg = (f'{Y}/{M}/{D} {h}:{m}:{s}.000 {tide}0000\\n')\n",
    "            new_msg = (f'{Y}/{M}/{D} {h}:{m}:{s} {tide}0000\\n')\n",
    "#             print(new_msg)\n",
    "            oFile_w.write(new_msg)\n",
    "    oFile_w.close()\n",
    "\n",
    "from pathlib import Path\n",
    "tide_data = r'D:\\DoTWA_Data\\202005_Patch\\202005_PatchTest\\Export'\n",
    "all_IN = [f for f in Path(tide_data).iterdir() if f.name.endswith('.csv')]\n",
    "for inFile_p in all_IN:\n",
    "    name = inFile_p.name.split('.')[0]\n",
    "    # oFile_p = Path(tide_data) / (Path(tide_data).name + '_Observed_UTC_merge.tide')\n",
    "    oFile_p = Path(tide_data) / (Path(tide_data).parent.name + '_Observed_UTC_merge.tide')\n",
    "    print(inFile_p,'\\n',oFile_p)\n",
    "    LOCAL2UTC_tide(inFile_p,oFile_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.12 202008_Patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.12.a Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "from pathlib import Path\n",
    "#input directories\n",
    "indir = r'D:\\DoTWA_Data\\202008_Patch\\DOT WA HANSEN 2020 PATCH 2\\Export'\n",
    "#input settings\n",
    "in_delimiter = ','\n",
    "in_Ext = '.txt'\n",
    "#Output settings\n",
    "out_header = 'N'\n",
    "out_delimiter = in_delimiter\n",
    "out_colNames=['Day','Time','Tide','unknown','unknown']\n",
    "out_Ext = '.csv'\n",
    "out_fname = Path(indir) / (Path(indir).parent.parent.name + '_Observed_AWST_merge' + out_Ext)\n",
    "colNames = str(out_colNames)[1:-2].replace(\"'\",\"\").replace(', ',out_delimiter)\n",
    "#Write header based on user input choice\n",
    "outfile = open(out_fname,'w')\n",
    "if out_header == 'Y':\n",
    "        outfile.write(colNames+'\\n')\n",
    "else: pass\n",
    "#Merging text files using pure Python\n",
    "all_In = [f.absolute() for f in Path(indir).iterdir() if f.name.endswith(in_Ext) ]\n",
    "\n",
    "skip_line = 5\n",
    "\n",
    "for fname in all_In:\n",
    "    if fname != out_fname:\n",
    "        with open(fname,'r') as infile:\n",
    "            for lineNo,line in enumerate(infile):\n",
    "                if lineNo >= skip_line:\n",
    "                    line = line.replace(in_delimiter,out_delimiter)\n",
    "                    if line != '\\n': \n",
    "                        outfile.write(line)\n",
    "    #                     print(line)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.12.b Local time to UTC Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\DoTWA_Data\\202008_Patch\\DOT WA HANSEN 2020 PATCH 2\\Export\\202008_Patch_Observed_AWST_merge.csv \n",
      " D:\\DoTWA_Data\\202008_Patch\\DOT WA HANSEN 2020 PATCH 2\\Export\\202008_Patch_Observed_UTC_merge.tide\n"
     ]
    }
   ],
   "source": [
    "def LOCAL2UTC_tide(inFile_p,oFile_p):\n",
    "    import os\n",
    "    import sys\n",
    "    from datetime import datetime\n",
    "    from datetime import timedelta\n",
    "    \n",
    "    dt_format1 = \"%Y-%m-%d %H:%M:%S\"\n",
    "    dt_format2 = \"%Y-%m-%d %H:%M:%S %Z%z\"\n",
    "    dt_format2a = \"%Y-%m-%d %H:%M:%S\"\n",
    "    dt_format2b = \"%Y-%m-%d %H:%M:%S.%f\"\n",
    "    dt_format3 = \"%d/%m/%Y%H:%M\"\n",
    "    dt_format4 = \"%d/%m/%Y %H:%M\"\n",
    "    dt_format5 = \"%Y-%m-%d %H:%M:%S.000\"\n",
    "    dt_format6 = \"%Y-%m-%d %H:%M:%S.%f\"\n",
    "    dt_format6_DoTWA = \"%d/%m/%Y,%H:%M:%S\"\n",
    "    dt_format6_DoTWA3 = \"%Y-%m-%d,%H:%M:%S\"\n",
    "    dt_format6_DoTWA4 = '%Y-%m-%dT%H:%M:%S+08:00'\n",
    "    oFile_w = open(oFile_p,'w')\n",
    "    skip = 0\n",
    "    \n",
    "    with open(inFile_p,'r') as infile:\n",
    "        msg = '--------\\n'\n",
    "        oFile_w.write(msg)\n",
    "        for counter,line in enumerate(infile):\n",
    "            if counter < skip: continue\n",
    "            # if counter < 15:\n",
    "            line = line.strip('\\n')\n",
    "            line_list = line.split(' ')\n",
    "            # line_list = line.split(',')\n",
    "            line_list2 = []\n",
    "            for l in line_list: line_list2.append(l.strip(' ')) #strip the space in list element if it presents\n",
    "            tide_str = float(line_list2[2])\n",
    "            tide_str = f'{tide_str:.3f}'\n",
    "            dt_str = line_list2[0] +' '+line_list2[1]\n",
    "            dt_obj_local = datetime.strptime(dt_str, dt_format6)\n",
    "            dt_txt_local = dt_obj_local.strftime(dt_format2b)\n",
    "#             print ('Local:',dt_txt_local,'Tide:',tide_str)\n",
    "            \n",
    "            # Convert to UTC (+00)\n",
    "            local_zone = 8\n",
    "            offset_h = -local_zone\n",
    "            offset_h_dt_oj = timedelta(hours = offset_h)\n",
    "            dt_obj_UTC = dt_obj_local + offset_h_dt_oj\n",
    "            dt_txt_UTC = dt_obj_UTC.strftime(dt_format2b)\n",
    "#             print ('UTC:',dt_txt_UTC,'Tide:',tide_str)\n",
    "#             print('\\tOffset: ',(offset_h_dt_oj.seconds)/3600+(offset_h_dt_oj.days)*24,'from local:',local_zone)\n",
    "    \n",
    "            # Convert to Perth (+08)\n",
    "            # zone_AEDT = 11\n",
    "            # zone_Perth = 8\n",
    "            # offset_h = zone_Perth-zone_AEDT\n",
    "            # offset_h_dt_oj = timedelta(hours = offset_h)\n",
    "            # dt_obj_perth = dt_obj_AEDT + offset_h_dt_oj\n",
    "            # dt_txt_perth = dt_obj_perth.strftime(dt_format2)\n",
    "            # print ('Perth:',dt_txt_perth,'Tide:',tide_str)\n",
    "            # print('\\tOffset: ',(offset_h_dt_oj.seconds)/3600+(offset_h_dt_oj.days)*24,'from AEDT:',zone_AEDT)\n",
    "    \n",
    "            line = dt_txt_UTC\n",
    "            Y = line[:4]\n",
    "            M = line[5:7]\n",
    "            D = line[8:10]\n",
    "            h = line[11:13]\n",
    "            m = line[14:16]\n",
    "            # s = line[17:19]\n",
    "            s = line[17:23]\n",
    "            tide = tide_str\n",
    "#             new_msg = (f'{Y}/{M}/{D} {h}:{m}:{s}.000 {tide}0000\\n')\n",
    "            new_msg = (f'{Y}/{M}/{D} {h}:{m}:{s} {tide}0000\\n')\n",
    "#             print(new_msg)\n",
    "            oFile_w.write(new_msg)\n",
    "    oFile_w.close()\n",
    "\n",
    "from pathlib import Path\n",
    "tide_data = r'D:\\DoTWA_Data\\202008_Patch\\DOT WA HANSEN 2020 PATCH 2\\Export'\n",
    "all_IN = [f for f in Path(tide_data).iterdir() if f.name.endswith('.csv')]\n",
    "for inFile_p in all_IN:\n",
    "    name = inFile_p.name.split('.')[0]\n",
    "    # oFile_p = Path(tide_data) / (Path(tide_data).name + '_Observed_UTC_merge.tide')\n",
    "    oFile_p = Path(tide_data) / (Path(tide_data).parent.parent.name + '_Observed_UTC_merge.tide')\n",
    "    print(inFile_p,'\\n',oFile_p)\n",
    "    LOCAL2UTC_tide(inFile_p,oFile_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.13 Merge all observed tide together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.13.a Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "from pathlib import Path\n",
    "#input directories\n",
    "indir = r'D:\\OneDrive - Curtin University of Technology Australia\\write\\c3_vU\\Observed_Tide\\All_Merged_Tide'\n",
    "#input settings\n",
    "# in_delimiter = ','\n",
    "in_delimiter = ' '\n",
    "in_Ext = '.tide'\n",
    "#Output settings\n",
    "out_header = 'N'\n",
    "out_delimiter = in_delimiter\n",
    "out_colNames=['Day','Time','Tide','unknown','unknown']\n",
    "out_Ext = '.tid'\n",
    "# out_fname = Path(indir) / (Path(indir).parent.parent.name + '_Predicted_LAT_UTC_merge' + out_Ext)\n",
    "out_fname = Path(indir) / (Path(indir).parent.parent.name + '_Observed_FreoLAT_UTC_merge' + out_Ext)\n",
    "colNames = str(out_colNames)[1:-2].replace(\"'\",\"\").replace(', ',out_delimiter)\n",
    "#Write header based on user input choice\n",
    "outfile = open(out_fname,'w')\n",
    "if out_header == 'Y':\n",
    "        outfile.write(colNames+'\\n')\n",
    "else: pass\n",
    "outfile.write('--------'+'\\n')\n",
    "#Merging text files using pure Python\n",
    "# all_In = [f.absolute() for f in Path(indir).iterdir() if (f.name.endswith(in_Ext) and '_Predicted_UTC_LAT' in f.name) ]\n",
    "all_In = [f.absolute() for f in Path(indir).iterdir() if (f.name.endswith(in_Ext) and '_Observed_UTC_merge' in f.name) ]\n",
    "\n",
    "skip_line = 1\n",
    "\n",
    "for fname in all_In:\n",
    "    if fname != out_fname:\n",
    "        with open(fname,'r') as infile:\n",
    "            for lineNo,line in enumerate(infile):\n",
    "                if lineNo >= skip_line:\n",
    "                    line = line.replace(in_delimiter,out_delimiter)\n",
    "                    if line != '\\n': \n",
    "                        outfile.write(line)\n",
    "    #                     print(line)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Predicted tide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.a Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "from pathlib import Path\n",
    "#input directories\n",
    "indir = r'D:\\OneDrive - Curtin University of Technology Australia\\write\\c3_vU\\Observed_Tide\\All_Merged_Tide'\n",
    "#input settings\n",
    "# in_delimiter = ','\n",
    "in_delimiter = ' '\n",
    "in_Ext = '.tide'\n",
    "#Output settings\n",
    "out_header = 'N'\n",
    "out_delimiter = in_delimiter\n",
    "out_colNames=['Day','Time','Tide','unknown','unknown']\n",
    "out_Ext = '.tid'\n",
    "out_fname = Path(indir) / (Path(indir).parent.parent.name + '_Predicted_LAT_UTC_merge' + out_Ext)\n",
    "# out_fname = Path(indir) / (Path(indir).parent.parent.name + '_Observed_FreoLAT_UTC_merge' + out_Ext)\n",
    "colNames = str(out_colNames)[1:-2].replace(\"'\",\"\").replace(', ',out_delimiter)\n",
    "#Write header based on user input choice\n",
    "outfile = open(out_fname,'w')\n",
    "if out_header == 'Y':\n",
    "        outfile.write(colNames+'\\n')\n",
    "else: pass\n",
    "outfile.write('--------'+'\\n')\n",
    "#Merging text files using pure Python\n",
    "all_In = [f.absolute() for f in Path(indir).iterdir() if (f.name.endswith(in_Ext) and '_Predicted_UTC_LAT' in f.name) ]\n",
    "# all_In = [f.absolute() for f in Path(indir).iterdir() if (f.name.endswith(in_Ext) and '_Observed_UTC_merge' in f.name) ]\n",
    "\n",
    "skip_line = 1\n",
    "\n",
    "for fname in all_In:\n",
    "    if fname != out_fname:\n",
    "        with open(fname,'r') as infile:\n",
    "            for lineNo,line in enumerate(infile):\n",
    "                if lineNo >= skip_line:\n",
    "                    line = line.replace(in_delimiter,out_delimiter)\n",
    "                    if line != '\\n': \n",
    "                        outfile.write(line)\n",
    "    #                     print(line)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "79824e13ff167d38e8fc726a2b68ab89d4c785b667ab6374278d212cf0cace44"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
